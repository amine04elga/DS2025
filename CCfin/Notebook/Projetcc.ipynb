# Installation de ucimlrepo
!pip install ucimlrepo

# Importation des biblioth√®ques
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from ucimlrepo import fetch_ucirepo
import warnings
warnings.filterwarnings('ignore')

# Configuration de l'affichage
plt.style.use('default')
sns.set_palette("husl")
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)

# ============================================================
# 2. CHARGEMENT DES DONN√âES
# ============================================================

print("=" * 80)
print("CHARGEMENT DES DONN√âES AIR QUALITY")
print("=" * 80)

# R√©cup√©ration du dataset
air_quality = fetch_ucirepo(id=360)

# Extraction des features et targets
X = air_quality.data.features
y = air_quality.data.targets

# Combinaison des donn√©es
df = pd.concat([X, y], axis=1)

print(f"\n‚úì Dataset charg√© avec succ√®s!")
print(f"  - Nombre de lignes: {df.shape[0]:,}")
print(f"  - Nombre de colonnes: {df.shape[1]}")

# ============================================================
# 3. APER√áU G√âN√âRAL DES DONN√âES
# ============================================================

print("\n" + "=" * 80)
print("APER√áU G√âN√âRAL DES DONN√âES")
print("=" * 80)

print("\nüìä Premi√®res lignes du dataset:")
print(df.head(10))

print("\nüìã Derni√®res lignes du dataset:")
print(df.tail(10))

print("\nüîç Informations sur les colonnes:")
print(df.info())

# ============================================================
# 4. STRUCTURE ET TYPES DE DONN√âES
# ============================================================

print("\n" + "=" * 80)
print("STRUCTURE ET TYPES DE DONN√âES")
print("=" * 80)

print("\nüìù Types de donn√©es par colonne:")
for col in df.columns:
    print(f"  - {col:30s} : {str(df[col].dtype):15s} | Exemple: {df[col].iloc[0]}")

# ============================================================
# 5. VALEURS MANQUANTES
# ============================================================

print("\n" + "=" * 80)
print("ANALYSE DES VALEURS MANQUANTES")
print("=" * 80)

# Remplacement des valeurs -200 par NaN (comme sp√©cifi√© dans la documentation)
df_clean = df.replace(-200, np.nan)

missing_data = pd.DataFrame({
    'Nombre de valeurs manquantes': df_clean.isnull().sum(),
    'Pourcentage (%)': (df_clean.isnull().sum() / len(df_clean) * 100).round(2)
})
missing_data = missing_data[missing_data['Nombre de valeurs manquantes'] > 0].sort_values(
    by='Nombre de valeurs manquantes', ascending=False
)

if len(missing_data) > 0:
    print("\n‚ö†Ô∏è Colonnes avec valeurs manquantes:")
    print(missing_data)
    
    # Visualisation des valeurs manquantes
    plt.figure(figsize=(12, 6))
    missing_data['Pourcentage (%)'].plot(kind='barh', color='coral')
    plt.xlabel('Pourcentage de valeurs manquantes (%)')
    plt.title('Distribution des valeurs manquantes par variable')
    plt.tight_layout()
    plt.show()
else:
    print("\n‚úì Aucune valeur manquante d√©tect√©e!")

# ============================================================
# 6. STATISTIQUES DESCRIPTIVES
# ============================================================

print("\n" + "=" * 80)
print("STATISTIQUES DESCRIPTIVES")
print("=" * 80)

# S√©lection des colonnes num√©riques uniquement
numeric_cols = df_clean.select_dtypes(include=[np.number]).columns

print("\nüìà Statistiques descriptives des variables num√©riques:")
stats_desc = df_clean[numeric_cols].describe()
print(stats_desc.round(2))

# Statistiques suppl√©mentaires
print("\nüìä Statistiques suppl√©mentaires:")
additional_stats = pd.DataFrame({
    'M√©diane': df_clean[numeric_cols].median(),
    'Variance': df_clean[numeric_cols].var(),
    '√âcart-type': df_clean[numeric_cols].std(),
    'Asym√©trie (Skewness)': df_clean[numeric_cols].skew(),
    'Aplatissement (Kurtosis)': df_clean[numeric_cols].kurtosis()
})
print(additional_stats.round(2))

# ============================================================
# 7. DISTRIBUTION DES VARIABLES
# ============================================================

print("\n" + "=" * 80)
print("DISTRIBUTION DES VARIABLES")
print("=" * 80)

# Identification des variables de polluants (GT = Ground Truth)
pollutant_cols = [col for col in df_clean.columns if 'GT' in col and col != 'Date']
sensor_cols = [col for col in df_clean.columns if 'PT08' in col]

# Distribution des polluants
if len(pollutant_cols) > 0:
    n_cols = 3
    n_rows = int(np.ceil(len(pollutant_cols) / n_cols))
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))
    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes
    
    for idx, col in enumerate(pollutant_cols):
        data = df_clean[col].dropna()
        axes[idx].hist(data, bins=50, color='skyblue', edgecolor='black', alpha=0.7)
        axes[idx].set_title(f'Distribution de {col}')
        axes[idx].set_xlabel('Valeur')
        axes[idx].set_ylabel('Fr√©quence')
        axes[idx].grid(True, alpha=0.3)
    
    # Masquer les axes inutilis√©s
    for idx in range(len(pollutant_cols), len(axes)):
        axes[idx].axis('off')
    
    plt.tight_layout()
    plt.show()

# ============================================================
# 8. BOXPLOTS POUR D√âTECTER LES OUTLIERS
# ============================================================

print("\n" + "=" * 80)
print("D√âTECTION DES VALEURS ABERRANTES (OUTLIERS)")
print("=" * 80)

if len(pollutant_cols) > 0:
    fig, axes = plt.subplots(1, len(pollutant_cols), figsize=(15, 5))
    if len(pollutant_cols) == 1:
        axes = [axes]
    
    for idx, col in enumerate(pollutant_cols):
        data = df_clean[col].dropna()
        axes[idx].boxplot(data, vert=True)
        axes[idx].set_title(f'{col}')
        axes[idx].set_ylabel('Valeur')
        axes[idx].grid(True, alpha=0.3)
    
    plt.suptitle('Boxplots des polluants - D√©tection des outliers', fontsize=14, y=1.02)
    plt.tight_layout()
    plt.show()

# Calcul du nombre d'outliers par variable
print("\nüìä Nombre d'outliers par variable (m√©thode IQR):")
for col in pollutant_cols:
    Q1 = df_clean[col].quantile(0.25)
    Q3 = df_clean[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df_clean[(df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)][col]
    print(f"  - {col:20s} : {len(outliers):5d} outliers ({len(outliers)/len(df_clean)*100:.2f}%)")

# ============================================================
# 9. MATRICE DE CORR√âLATION
# ============================================================

print("\n" + "=" * 80)
print("ANALYSE DES CORR√âLATIONS")
print("=" * 80)

# Matrice de corr√©lation pour les variables num√©riques
correlation_matrix = df_clean[numeric_cols].corr()

# Visualisation
plt.figure(figsize=(14, 12))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
            center=0, square=True, linewidths=0.5, cbar_kws={"shrink": 0.8})
plt.title('Matrice de corr√©lation entre les variables', fontsize=14, pad=20)
plt.tight_layout()
plt.show()

# Affichage des corr√©lations les plus fortes
print("\nüîó Top 10 des corr√©lations positives (hors diagonale):")
corr_pairs = correlation_matrix.unstack()
corr_pairs = corr_pairs[corr_pairs < 1]  # Exclure les corr√©lations parfaites (diagonale)
top_positive = corr_pairs.sort_values(ascending=False).head(10)
for (var1, var2), corr in top_positive.items():
    print(f"  - {var1:20s} ‚Üî {var2:20s} : {corr:.3f}")

print("\nüîó Top 10 des corr√©lations n√©gatives:")
top_negative = corr_pairs.sort_values(ascending=True).head(10)
for (var1, var2), corr in top_negative.items():
    print(f"  - {var1:20s} ‚Üî {var2:20s} : {corr:.3f}")

# ============================================================
# 10. ANALYSE TEMPORELLE (si Date disponible)
# ============================================================

print("\n" + "=" * 80)
print("ANALYSE TEMPORELLE")
print("=" * 80)

if 'Date' in df_clean.columns:
    # Conversion en datetime si n√©cessaire
    if df_clean['Date'].dtype == 'object':
        df_clean['Date'] = pd.to_datetime(df_clean['Date'], errors='coerce')
    
    # Extraction des composantes temporelles
    df_clean['Year'] = df_clean['Date'].dt.year
    df_clean['Month'] = df_clean['Date'].dt.month
    df_clean['Day'] = df_clean['Date'].dt.day
    df_clean['DayOfWeek'] = df_clean['Date'].dt.dayofweek
    
    print(f"\nüìÖ P√©riode couverte:")
    print(f"  - Date de d√©but: {df_clean['Date'].min()}")
    print(f"  - Date de fin: {df_clean['Date'].max()}")
    print(f"  - Dur√©e totale: {(df_clean['Date'].max() - df_clean['Date'].min()).days} jours")
    
    # √âvolution temporelle des polluants principaux
    if len(pollutant_cols) > 0:
        fig, axes = plt.subplots(len(pollutant_cols), 1, figsize=(15, 3*len(pollutant_cols)))
        if len(pollutant_cols) == 1:
            axes = [axes]
        
        for idx, col in enumerate(pollutant_cols):
            data_plot = df_clean[['Date', col]].dropna()
            axes[idx].plot(data_plot['Date'], data_plot[col], linewidth=0.5, alpha=0.7)
            axes[idx].set_title(f'√âvolution temporelle de {col}')
            axes[idx].set_xlabel('Date')
            axes[idx].set_ylabel('Concentration')
            axes[idx].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()

# ============================================================
# 11. R√âSUM√â FINAL
# ============================================================

print("\n" + "=" * 80)
print("R√âSUM√â DE L'ANALYSE")
print("=" * 80)

print(f"""
üìä DIMENSIONS DU DATASET
  - Nombre total d'observations: {df.shape[0]:,}
  - Nombre de variables: {df.shape[1]}
  - Variables num√©riques: {len(numeric_cols)}
  - Variables avec valeurs manquantes: {len(missing_data)}

üî¨ VARIABLES PRINCIPALES
  - Polluants mesur√©s (Ground Truth): {len(pollutant_cols)}
  - Capteurs (PT08.Sx): {len(sensor_cols)}

‚ö†Ô∏è QUALIT√â DES DONN√âES
  - Observations compl√®tes: {df_clean.dropna().shape[0]:,} ({df_clean.dropna().shape[0]/len(df_clean)*100:.2f}%)
  - Observations avec valeurs manquantes: {df_clean.isnull().any(axis=1).sum():,}

üìà CARACT√âRISTIQUES
  - Pr√©sence de valeurs aberrantes (outliers) d√©tect√©es
  - Corr√©lations fortes entre certaines variables
  - Donn√©es de s√©ries temporelles sur une ann√©e compl√®te
""")

print("\n‚úì Analyse descriptive termin√©e!")
print("=" * 80)
